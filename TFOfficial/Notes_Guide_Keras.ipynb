{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Guide: Keras\n",
    "\n",
    "This notes summarize TensorFlow Guide on Keras, from https://www.tensorflow.org/guide/keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. The sequential model\n",
    "\n",
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "It behaves very much like a list of layers. In particular, it can be created by passing a list of layers to the Sequential constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 4)                 16        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(4,)),\n",
    "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(4, name=\"layer3\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few more comments on the Sequential and its components\n",
    " - The inputs returned from keras.Input() contains information about the shape and dtype of the input data\n",
    "   - Batch size is always omitted from shape\n",
    "   - keras.Input() may be replaced by passing input_shape=(4,) to the 1st layer (layer1 above)\n",
    " - In parallel with list behavior, model.add() and model.pop() adds and removes layer\n",
    "   - One can use .add() and .summary() to inspect the architecture, namely, input and output dimensions\n",
    " - layer.dense() returns layer, a function-like class\n",
    "   - y=layer(x)\n",
    "   - layer.output field contains layer's output\n",
    "   - layer.weights data field\n",
    " - model.layers behave like a list of layers\n",
    "   - outputs=[layer.output for layer in model.layers] gathers all layers' outputs\n",
    " - model.get_layer(name='layer1') gets layer by name\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1 Transfer learning with sequential learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II Keras functional API\n",
    "\n",
    "This API is used to created model more flexible than sequntial model. It can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
    "\n",
    "The <b>main idea</b> is that a deep learning model is usually a directed acyclic graph (DAG) of layers. Using the functional API to feed one layer's output to another's input, one establish a DAG (of layers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,))    # Input, note batch size is omitted\n",
    "dense = layers.Dense(64, activation=\"relu\") # 1st layer\n",
    "x = dense(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\")(x) # 2nd layer\n",
    "outputs = layers.Dense(10)(x)  # 3rd layer\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model can be displayed as a graph below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_first_model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1. Use the same graph of layers to define multiple models\n",
    "\n",
    "In the functional API, models are created by specifying their inputs and outputs in a graph of layers. That means that a single graph of layers can be used to generate multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. All models are callable, just like layers -- connecting and nesting models\n",
    "\n",
    "You can treat any model as if it were a layer by invoking it on an Input or on the output of another layer. By calling a model you aren't just reusing the architecture of the model, you're also reusing its weights.\n",
    "\n",
    "In the example below, we define an encoder model and a decoder model. Then we connect them to form a autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "original_img (InputLayer)    [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_img (InputLayer)     [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 9,569\n",
      "Trainable params: 9,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                18672     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         9569      \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
    "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can also be nested: a model can contain sub-models (since a model is just like a layer). A common use case for model nesting is ensembling. For example, here's how to ensemble a set of models into a single model that averages their predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(128,))\n",
    "    outputs = layers.Dense(1)(inputs)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "model1 = get_model()\n",
    "model2 = get_model()\n",
    "model3 = get_model()\n",
    "\n",
    "inputs = keras.Input(shape=(128,))\n",
    "y1 = model1(inputs)\n",
    "y2 = model2(inputs)\n",
    "y3 = model3(inputs)\n",
    "outputs = layers.average([y1, y2, y3])\n",
    "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3. Manipulate complex graph topologies\n",
    "[Yet to read]\n",
    "\n",
    "With functional API, one can\n",
    " - Construct models with multiple inputs and outputs\n",
    " - Include non-linear connectivity topology -- A toy ResNet model\n",
    " - Share layers\n",
    " - Extract and reuse nodes in the graph of layers\n",
    " - Extend the API using custom layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.4 When to use the functional API\n",
    "[Yet to read]\n",
    "\n",
    "Two alternatives\n",
    " - Functional API\n",
    " - Model subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.5 Directly subclass \n",
    "[Yet to read]\n",
    "\n",
    "All models in the tf.keras API can interact with each other. For example, one can use a functional model or Sequential model as part of a subclassed model or layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Training and evaluation with the built-in methods\n",
    "\n",
    "This section covers training, evaluation, and prediction (inference) models when using built-in APIs for training & validation (such as model.fit(), model.evaluate(), model.predict()).\n",
    "\n",
    "If you are interested in leveraging fit() while specifying your own training step function, see the guide \"customizing what happens in fit()\".\n",
    "\n",
    "If you are interested in writing your own training & evaluation loops from scratch, see the guide \"writing a training loop from scratch\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.1 API overview: a first end-to-end example\n",
    "\n",
    "When passing data to the built-in training loops of a model, you should either use NumPy arrays (if your data is small and fits in memory) or tf.data Dataset objects. A typical training workflow consists of the following steps\n",
    " - Split data into train, validation, and test sets\n",
    " - Specify model, using keras.Sequential, functional API, Model subclassing, etc.\n",
    "   - We end up with a model object, call it model\n",
    " - Specify the training configuration (optimizer, loss, and optianally metrics to monitor)\n",
    "   - Using model.compile\n",
    " - Call history=model.fit() to train the model\n",
    "   - It slices the data into \"batches\" of size \"batch_size\", and\n",
    "   - It repeatedly iterate over the entire dataset for a given number of \"epochs\".\n",
    " - The returned \"history\" object holds a record of the loss values and metric values during training\n",
    "   - In history.history\n",
    " - We evaluate the model on the test data via model.evaluate()\n",
    "   - It returns loss and accuracy\n",
    " - We can obtain prediction by calling model.predict()\n",
    "\n",
    "#### III.1.A Custom losses\n",
    "[Yet to read]\n",
    "\n",
    "\n",
    "#### III.1.B Custom metrics\n",
    "[Yet to read]\n",
    "\n",
    "\n",
    "#### III.1.C Handling losses and metrics that don't fit the standard signature\n",
    "[Yet to read]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2 Training and evaluation from tf.data Datasets\n",
    "[Yet to read]\n",
    "\n",
    "\n",
    "#### III.2.B Other input formats supported\n",
    "\n",
    "Besides NumPy arrays, eager tensors, and TensorFlow Datasets, it's possible to train a Keras model using Pandas dataframes, or from Python generators that yield batches of data & labels.\n",
    "\n",
    "In particular, the keras.utils.Sequence class offers a simple interface to build Python data generators that are multiprocessing-aware and can be shuffled.\n",
    "\n",
    "In general, we recommend that you use:\n",
    " - NumPy input data if your data is small and fits in memory\n",
    " - Dataset objects if you have large datasets and you need to do distributed training\n",
    " - Sequence objects if you have large datasets and you need to do a lot of custom Python-side processing that cannot be done in TensorFlow (e.g. if you rely on external libraries for data loading or preprocessing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.3. Using sample weighting and class weighting\n",
    "\n",
    "Class weight is set by passing a dictionary to the class_weight argument to Model.fit(). This dictionary maps class indices to the weight that should be used for samples belonging to this class.\n",
    "\n",
    "For fine grained control, or if you are not building a classifier, you can use \"sample weights\".\n",
    " - When training from NumPy data: Pass the sample_weight argument to Model.fit().\n",
    " - When training from tf.data or any other sort of iterator: Yield (input_batch, label_batch, sample_weight_batch) tuples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.4. Passing data to multi-input, multi-output models\n",
    "[Yet to read]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5. Using callbacks\n",
    "\n",
    "Callbacks in Keras are objects that are called at different points during training (at the start of an epoch, at the end of a batch, at the end of an epoch, etc.) and which can be used to implement behaviors such as:\n",
    " - Doing validation at different points during training (beyond the built-in per-epoch validation)\n",
    " - Checkpointing the model at regular intervals or when it exceeds a certain accuracy threshold\n",
    " - Changing the learning rate of the model when training seems to be plateauing\n",
    " - Doing fine-tuning of the top layers when training seems to be plateauing\n",
    " - Sending email or instant message notifications when training ends or where a certain performance threshold is exceeded\n",
    " - Etc.\n",
    " \n",
    "Many built-in callbacks are available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.6. Checkpointing models\n",
    "\n",
    "When you're training model on relatively large datasets, it's crucial to save checkpoints of your model at frequent intervals.\n",
    "\n",
    "The easiest way to achieve this is with the ModelCheckpoint callback:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.7. Using learning rate schedules\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.8. Visualizing loss and metrics during training\n",
    "\n",
    "The best way to keep an eye on your model during training is to use TensorBoard, a browser-based application that you can run locally that provides you with:\n",
    " - Live plots of the loss and metrics for training and evaluation\n",
    " - (optionally) Visualizations of the histograms of your layer activations\n",
    " - (optionally) 3D visualizations of the embedding spaces learned by your Embedding layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
